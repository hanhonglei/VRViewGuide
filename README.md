# Object-based Visual Attention Quantification Using Head Orientation in VR Applications
This paper presents a method to measure what and how deep the user can perceive when exploring virtual reality environments using a head mounted display. A preliminary user study was conducted to verify that user gaze behavior has specific differences in immersive virtual reality environments compared with that in conventional, non-immersive virtual reality environments, which are based on a desktop screen. Gathered from the study result for gaze behavior, the users experiencing immersive virtual reality environments are more likely to adjust their head movement to center interesting objects in their vision. Based on this finding, a quantitative method is proposed to measure the user's visual attention in such a virtual reality environment. In application part, a user personalized storyboard has been designed to capture the user's most regarded views as key frames that can depict users' exploration experience in immersive virtual reality environments. 

The source project of user study and personalized storyboard demo can be found in [Bitbucket Repository](https://bitbucket.org/Honglei_Han/viewguideuserstudyvrlimitedsize).

Here is the [executable program](https://github.com/hanhonglei/VRViewGuide/blob/master/UserStudyAppliction.zip)

Here is the [complete user study results](https://github.com/hanhonglei/VRViewGuide/tree/master/UserStudyResult)

Here is the [introduction video](https://github.com/hanhonglei/VRViewGuide/blob/master/IntroductionVideo.mp4)

And a brief introduction slider can be downloaded [here](https://github.com/hanhonglei/VRViewGuide/blob/master/BriefIntro.ppsx)

----

- This project is under [GNU GENERAL PUBLIC LICENSE](https://www.gnu.org/licenses/), please check it in the root folder.